# Regex Text Preprocessing

![Logo](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTF-ufT8Iv0WrSGuzR_JOId0cqGpUrnZ6m4pg&s)

This repository provides a robust, configurable, and extensible text preprocessing engine built in Python. It is tailored for NLP applications, including sentiment analysis, emotion detection, and general dataset cleaning. The library uses advanced regular expressions to deliver fast, reliable, and comprehensive text normalization for machine learning workflows.

<br/>

## âœ¨ Features
* 18 Preprocessing Steps - Comprehensive text cleaning pipeline
  * URL replacement and preservation
  * Email address handling
  * Date/time normalization
  * Currency and monetary value processing
  * Social media entity expansion (@mentions, #hashtags, $cashtags)
  * HTML tag removal
  * Slang word replacement
  * Contraction expansion
  * Stopword removal (with negation preservation)
  * Title removal (Mr., Dr., etc.)
  * Number and punctuation cleaning
  * Repeated character normalization
* Flexible Configuration - Enable/disable any preprocessing step
* Protection Mechanism - Preserves important entities (URLs, emails) from deletion
* Pre-compiled Regex - Optimized patterns for fast processing
* Batch Processing - Efficiently handles multiple CSV files
* Dictionary Export - Saves replaced entities for reverse mapping

<br/>

## ğŸ“š Documentation

[English Documentation](documents/Preprocessing_Document_English.pdf) \
[Persian Documentation](documents/Preprocessing_Document_Persian.pdf)

<br/>

## ğŸ”„ Preprocessing Pipeline
The preprocessing follows this carefully ordered sequence:

| Step | Operation               | Description                                           |
|------|--------------------------|-------------------------------------------------------|
| 1    | Remove NULL values       | Drops rows with missing data                          |
| 2    | Replace URLs             | Protects and maps web addresses                       |
| 3    | Replace Emails           | Protects and maps email addresses                     |
| 4    | Replace Time             | Normalizes time formats                               |
| 5    | Replace Money            | Handles currency symbols and amounts                  |
| 6    | Expand Mentions          | Converts `@user_name` â†’ `user name`                   |
| 7    | Expand Hashtags          | Converts `#hash_tag` â†’ `hash tag`                     |
| 8    | Remove HTML Tags         | Strips `<div>`, `<p>`, etc.                           |
| 9    | Remove Cashtags          | Removes stock symbols like `$AAPL`                    |
| 10   | Expand Contractions      | `don't` â†’ `do not`                                    |
| 11   | Replace Slang Words      | `ur` â†’ `your`, `brb` â†’ `be right back`                |
| 12   | Convert to Lowercase     | Normalizes case                                       |
| 13   | Remove Dates             | Strips date patterns                                  |
| 14   | Remove Stopwords         | Removes common words (preserves negations)            |
| 15   | Remove Titles            | Removes `Mr.`, `Dr.`, `Prof.`, etc.                   |
| 16   | Remove Numbers           | Deletes numeric values (protects markers)             |
| 17   | Remove Punctuation       | Strips special characters (protects markers)          |
| 18   | Replace Repeated Letters | `Gooooood` â†’ `Good`                                   |

<br/>

## ğŸ“ Project Structure
```
ğŸ“¦ Project Root
â”‚
â”œâ”€â”€Â ğŸ“‚ data
â”‚Â Â   â”œâ”€â”€ ğŸ“‚Â processed                      # Output cleaned files
â”‚  Â Â â”‚Â Â   â”œâ”€â”€Â ğŸ“‚ maps                      # Saved dictionaries (.pkl files)
â”‚Â Â   â”‚Â   Â â”‚Â   Â â”œâ”€â”€Â ğŸ“„ money_dictionary.pkl
â”‚Â Â   â”‚Â Â   â”‚Â   Â â”œâ”€â”€Â ğŸ“„ time_dictionary.pkl
â”‚Â Â   â”‚Â Â   â”‚Â   Â â””â”€â”€Â ğŸ“„ urls_dictionary.pkl
â”‚    â”‚    â”‚
â”‚Â Â   â”‚Â   Â â”œâ”€â”€Â ğŸ“œ test_clean.csv
â”‚Â Â   â”‚Â Â   â””â”€â”€Â ğŸ“œ train_clean.csv
â”‚    â”‚
â”‚Â Â   â””â”€â”€Â ğŸ“‚ raw                           # Input CSV files
â”‚Â Â Â Â     Â â”œâ”€â”€Â ğŸ“œ test.csv
â”‚Â Â Â Â Â     â””â”€â”€Â ğŸ“œ train.csv
â”‚
â”œâ”€â”€Â ğŸ“‚ documents
â”‚  Â Â â”œâ”€â”€Â ğŸ“š Preprocessing_Document - English.pdf
â”‚Â Â   â””â”€â”€Â ğŸ“š Preprocessing_Document - Persian.pdf
â”‚
â”œâ”€â”€Â ğŸ“‚ resources
â”‚Â Â   â”œâ”€â”€Â ğŸ“Š English_Contractions.json
â”‚Â Â   â”œâ”€â”€Â ğŸ“Š English_Slang_Dict.json
â”‚Â Â   â””â”€â”€Â ğŸ“„ English_Stopwords_without_negatives.txt
â”‚
â”œâ”€â”€ ğŸ“‚ src
â”‚Â Â   â”œâ”€â”€Â ğŸ““ __init__.py
â”‚Â   Â â”œâ”€â”€Â ğŸ““ config.py                        # Configuration class
â”‚Â   Â â””â”€â”€Â ğŸ““ preprocessor.py                  # Main preprocessing logic
â”‚
â”œâ”€â”€ ğŸ““Â main.py                               # Entry point script
â”œâ”€â”€Â ğŸ“„ requirements.txt                      # Python dependencies
â””â”€â”€Â ğŸ“„ README.md
```

<br/>

## ğŸš€ Installation

Prerequisites
* Python 3.7 or higher
* pip package manager

Open your terminal (Command Prompt, PowerShell, or Terminal), navigate to your project folder:

Clone the Repository:
```bash
git clone `this repository`
cd text-preprocessing-regex
```


Install Dependencies (do this once):

```bash
  pip install -r requirements.txt
```

Run the Program:
```bash
  python main.py
```

<br/>

## Required Packages
```bash
pandas>=1.3.0
regex>=2021.8.3
```

<br/>

## ğŸ“– Citation
If you use this project in your research, please cite:
```
@inproceedings{tareh-etal-2025-iasbs,
    title = "{IASBS} at {S}em{E}val-2025 Task 11: Ensembling Transformers for Bridging the Gap in Text-Based Emotion Detection",
    author = "Tareh, Mehrzad  and
      Mohammadzadeh, Erfan  and
      Mohandesi, Aydin  and
      Ansari, Ebrahim",
    editor = "Rosenthal, Sara  and
      Ros{\'a}, Aiala  and
      Ghosh, Debanjan  and
      Zampieri, Marcos",
    booktitle = "Proceedings of the 19th International Workshop on Semantic Evaluation (SemEval-2025)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.semeval-1.96/",
    pages = "695--702",
    ISBN = "979-8-89176-273-2",
    abstract = "In this paper, we address the challenges of text-based emotion detection, focusing on multi-label classification, emotion intensity prediction, and cross-lingual emotion detection across various languages. We explore the use of advanced machine learning models, particularly transformers, in three tracks: emotion detection, emotion intensity prediction, and cross-lingual emotion detection. Our approach utilizes pre-trained transformer models, such as Gemini, DeBERTa, M-BERT, and M-DistilBERT, combined with techniques like majority voting and average ensemble voting (AEV) to enhance performance. We also incorporate multilingual strategies and prompt engineering to effectively handle the complexities of emotion detection across diverse linguistic and cultural contexts. Our findings demonstrate the success of ensemble methods and multilingual models in improving the accuracy and generalization of emotion detection, particularly for low-resource languages."
}
```

<br/>

## ğŸ“§ Contact
* Erfan Mohammadzadeh
* GitHub: [@e-mohammadzadeh](https://github.com/e-mohammadzadeh)
* LinkedIn: [erfan-mohammadzadeh](https://www.linkedin.com/in/erfan-mohammadzadeh/)

---

â­ Star this repository if you find it helpful!
Pull requests are welcome!
If you would like to add preprocessing steps, optimize regular expression speed, or enhance documentation, please feel free to open an issue.
Made with â¤ï¸ by Erfan Mohammadzadeh
